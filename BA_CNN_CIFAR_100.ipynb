{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BA_CNN_CIFAR_100.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvPb0YJNU1RM"
      },
      "source": [
        "\n",
        "<H3 align='center'> An Attention-Based Architecture for\n",
        "Hierarchical Classification with CNNs </H3>\n",
        "\n",
        "<H5 align='center'> CIFAR-100 </H3>\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dependencies"
      ],
      "metadata": {
        "id": "_zlvBmYMm1z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove \n",
        "print(\"Mounting your Google Drive ...\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive',force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAnQlSnPtp4q",
        "outputId": "77ad6506-50a2-42b9-e945-f72abddbdcac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting your Google Drive ...\n",
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vb27tNtvUuKD"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Concatenate, Add, Softmax\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, BatchNormalization\n",
        "from keras.initializers import he_normal\n",
        "from keras import optimizers\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard, CSVLogger\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import pickle\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import CSVLogger\n",
        "from tensorflow.keras.utils import set_random_seed\n",
        "from scipy import stats\n",
        "\n",
        "def unpickle(filename):\n",
        "  file = os.path.join(data_dir, filename)\n",
        "  with open(file, 'rb') as fo:\n",
        "    dict = pickle.load(fo, encoding='bytes')\n",
        "  return dict\n",
        "  \n",
        "# Computes hierarchical metrics proposed by Kiritchenko et al (2005)\n",
        "def hierarchical_metrics(true,pred):\n",
        "  true_labels = []\n",
        "  true_fine = true[2].argmax(axis=1)\n",
        "  true_c2 = true[1].argmax(axis=1)\n",
        "  true_c1 = true[0].argmax(axis=1)\n",
        "  for i in range(len(true_fine)):\n",
        "    true_labels.append([true_c1[i],true_c2[i],true_fine[i]])\n",
        "  pred_labels = []\n",
        "  pred_c1 = pred[0].argmax(axis = 1)\n",
        "  pred_c2 = pred[1].argmax(axis = 1)\n",
        "  pred_fine = pred[2].argmax(axis = 1) \n",
        "  for i in range(len(pred_c1)):\n",
        "    pred_labels.append([pred_c1[i],pred_c2[i],pred_fine[i]])\n",
        "  preci = precision(true_labels,pred_labels)\n",
        "  reca = recall(true_labels,pred_labels)\n",
        "  f_1 = f1(true_labels,pred_labels)\n",
        "  return preci,reca,f_1\n",
        "\n",
        "# Hierarchical metrics, proposed by Kiritchenko et al (2005)\n",
        "# Implementation \n",
        "# https://gitlab.com/dacs-hpi/hiclass/-/blob/main/hiclass/metrics.py\n",
        "\n",
        "def precision(y_true: np.ndarray, y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Compute precision score for hierarchical classification.\n",
        "\n",
        "    hP = sum(|S intersection T|) / sum(|S|),\n",
        "    where S is the set consisting of the most specific class(es) predicted for a test example and all respective ancestors\n",
        "    and T is the set consisting of the true most specific class(es) for a test example and all respective ancestors.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : np.array of shape (n_samples, n_levels)\n",
        "        Ground truth (correct) labels.\n",
        "    y_pred : np.array of shape (n_samples, n_levels)\n",
        "        Predicted labels, as returned by a classifier.\n",
        "    Returns\n",
        "    -------\n",
        "    precision : float\n",
        "        What proportion of positive identifications was actually correct?\n",
        "    \"\"\"\n",
        "    assert len(y_true) == len(y_pred)\n",
        "    sum_intersection = 0\n",
        "    sum_prediction_and_ancestors = 0\n",
        "    for ground_truth, prediction in zip(y_true, y_pred):\n",
        "        sum_intersection = sum_intersection + len(\n",
        "            set(ground_truth).intersection(set(prediction))\n",
        "        )\n",
        "        sum_prediction_and_ancestors = sum_prediction_and_ancestors + len(\n",
        "            set(prediction)\n",
        "        )\n",
        "    precision = sum_intersection / sum_prediction_and_ancestors\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true: np.ndarray, y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Compute recall score for hierarchical classification.\n",
        "\n",
        "    hR = sum(|S intersection T|) / sum(|T|),\n",
        "    where S is the set consisting of the most specific class(es) predicted for a test example and all respective ancestors\n",
        "    and T is the set consisting of the true most specific class(es) for a test example and all respective ancestors.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : np.array of shape (n_samples, n_levels)\n",
        "        Ground truth (correct) labels.\n",
        "    y_pred : np.array of shape (n_samples, n_levels)\n",
        "        Predicted labels, as returned by a classifier.\n",
        "    Returns\n",
        "    -------\n",
        "    recall : float\n",
        "        What proportion of actual positives was identified correctly?\n",
        "    \"\"\"\n",
        "    assert len(y_true) == len(y_pred)\n",
        "    sum_intersection = 0\n",
        "    sum_prediction_and_ancestors = 0\n",
        "    for ground_truth, prediction in zip(y_true, y_pred):\n",
        "        sum_intersection = sum_intersection + len(\n",
        "            set(ground_truth).intersection(set(prediction))\n",
        "        )\n",
        "        sum_prediction_and_ancestors = sum_prediction_and_ancestors + len(\n",
        "            set(ground_truth)\n",
        "        )\n",
        "    recall = sum_intersection / sum_prediction_and_ancestors\n",
        "    return recall\n",
        "\n",
        "\n",
        "def f1(y_true: np.ndarray, y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Compute f1 score for hierarchical classification.\n",
        "\n",
        "    hF = 2 * hP * hR / (hP + hR),\n",
        "    where hP is the hierarchical precision and hR is the hierarchical recall.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : np.array of shape (n_samples, n_levels)\n",
        "        Ground truth (correct) labels.\n",
        "    y_pred : np.array of shape (n_samples, n_levels)\n",
        "        Predicted labels, as returned by a classifier.\n",
        "    Returns\n",
        "    -------\n",
        "    f1 : float\n",
        "        Weighted average of the precision and recall\n",
        "    \"\"\"\n",
        "    assert len(y_true) == len(y_pred)\n",
        "    prec = precision(y_true, y_pred)\n",
        "    rec = recall(y_true, y_pred)\n",
        "    f1 = 2 * prec * rec / (prec + rec)\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#General settings"
      ],
      "metadata": {
        "id": "oluoWzPPi29B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/My Drive/ML/cifar-100-python\""
      ],
      "metadata": {
        "id": "ZvmwlcNdkT5w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-------- dimensions ---------\n",
        "height, width = 32, 32\n",
        "channel = 3\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (channel, height, width)\n",
        "else:\n",
        "    input_shape = (height, width, channel)\n",
        "#-----------------------------\n",
        "\n",
        "train_size = 50000\n",
        "test_size = 10000\n",
        "\n",
        "#--- coarse 1 classes ---\n",
        "coarse1_classes = 8\n",
        "#--- coarse 2 classes ---\n",
        "coarse2_classes = 20\n",
        "#--- fine classes ---\n",
        "num_classes  = 100\n",
        "\n",
        "batch_size   = 128\n",
        "epochs       = 80"
      ],
      "metadata": {
        "id": "ys4SZ4fti3Mr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch):\n",
        "  learning_rate_init = 0.001\n",
        "  if epoch > 55:\n",
        "    learning_rate_init = 0.0002\n",
        "  if epoch > 70:\n",
        "    learning_rate_init = 0.00005\n",
        "  return learning_rate_init"
      ],
      "metadata": {
        "id": "9VnZLarAjfDe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obs en implementacion decia epoch 13,23 y 33 , y en paper 10,20,30\n",
        "class LossWeightsModifier(keras.callbacks.Callback):\n",
        "  def __init__(self, alpha, beta, gamma):\n",
        "    self.alpha = alpha\n",
        "    self.beta = beta\n",
        "    self.gamma = gamma\n",
        "    # customize your behavior\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if epoch == 10:\n",
        "      K.set_value(self.alpha, 0.1)\n",
        "      K.set_value(self.beta, 0.8)\n",
        "      K.set_value(self.gamma, 0.1)\n",
        "    if epoch == 20:\n",
        "      K.set_value(self.alpha, 0.1)\n",
        "      K.set_value(self.beta, 0.2)\n",
        "      K.set_value(self.gamma, 0.7)\n",
        "    if epoch == 30:\n",
        "      K.set_value(self.alpha, 0)\n",
        "      K.set_value(self.beta, 0)\n",
        "      K.set_value(self.gamma, 1)"
      ],
      "metadata": {
        "id": "arduYBRPkQNC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------get VGG16 pre-trained weights--------\n",
        "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                         WEIGHTS_PATH,\n",
        "                         cache_subdir='models')\n",
        "\n",
        "#---------get data---------\n",
        "meta = unpickle(data_dir+\"/meta\")\n",
        "test = unpickle(data_dir+\"/test\")\n",
        "train = unpickle(data_dir+\"/train\")\n",
        "\n",
        "#-------------------- data loading ----------------------\n",
        "x_train = np.reshape(train[b'data'], (train_size, channel, height, width)).transpose(0, 2, 3, 1).astype(\"float32\")\n",
        "x_train = (x_train-np.mean(x_train)) / np.std(x_train)\n",
        "\n",
        "x_test = np.reshape(test[b'data'], (test_size, channel, height, width)).transpose(0, 2, 3, 1).astype(\"float32\")\n",
        "x_test = (x_test-np.mean(x_test)) / np.std(x_test)\n",
        "\n",
        "y_train = np.zeros((train_size, num_classes)).astype('float32')\n",
        "y_c2_train = np.zeros((train_size, coarse2_classes)).astype('float32')\n",
        "\n",
        "y_test = np.zeros((test_size, num_classes)).astype('float32')\n",
        "y_c2_test = np.zeros((test_size, coarse2_classes)).astype('float32')\n",
        "\n",
        "y_train[np.arange(train_size), train[b'fine_labels']] = 1\n",
        "y_c2_train[np.arange(train_size), train[b'coarse_labels']] = 1\n",
        "\n",
        "y_test[np.arange(test_size), test[b'fine_labels']] = 1\n",
        "y_c2_test[np.arange(test_size), test[b'coarse_labels']] = 1\n",
        "\n",
        "c2_to_f = np.zeros((coarse2_classes, num_classes)).astype('float32')\n",
        "fine_unique, fine_unique_indices = np.unique(train[b'fine_labels'], return_index=True)\n",
        "for i in fine_unique_indices:\n",
        "  c2_to_f[train[b'coarse_labels'][i]][train[b'fine_labels'][i]] = 1\n",
        "\n",
        "parent_c2 = {\n",
        "  0:0, 1:0, 2:1, 3:2, \n",
        "  4:1, 5:2, 6:2, 7:3, \n",
        "  8:4, 9:5, 10:5, 11:4, \n",
        "  12:4, 13:3, 14:6, 15:4, \n",
        "  16:4, 17:1, 18:7, 19:7\n",
        "}\n",
        "\n",
        "y_c1_train = np.zeros((y_c2_train.shape[0], coarse1_classes)).astype(\"float32\")\n",
        "y_c1_test = np.zeros((y_c2_test.shape[0], coarse1_classes)).astype(\"float32\")\n",
        "for i in range(y_c1_train.shape[0]):\n",
        "  y_c1_train[i][parent_c2[np.argmax(y_c2_train[i])]] = 1.0\n",
        "for i in range(y_c1_test.shape[0]):\n",
        "  y_c1_test[i][parent_c2[np.argmax(y_c2_test[i])]] = 1.0\n",
        "\n",
        "del(train)\n",
        "del(test)\n",
        "#---------------------------\n",
        "\n",
        "print(\"x_train shape: \", x_train.shape)\n",
        "print(\"x_test shape: \", x_test.shape)\n",
        "\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"y_test shape: \", y_test.shape)\n",
        "print(\"y_c1_train shape: \", y_c1_train.shape)\n",
        "print(\"y_c1_test shape: \", y_c1_test.shape)\n",
        "print(\"y_c2_train shape: \", y_c2_train.shape)\n",
        "print(\"y_c2_test shape: \", y_c2_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLK5dkIHkhcI",
        "outputId": "03ce3e1f-4249-4d69-e28c-bb4dfe4c3bdb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 70s 0us/step\n",
            "553476096/553467096 [==============================] - 70s 0us/step\n",
            "x_train shape:  (50000, 32, 32, 3)\n",
            "x_test shape:  (10000, 32, 32, 3)\n",
            "y_train shape:  (50000, 100)\n",
            "y_test shape:  (10000, 100)\n",
            "y_c1_train shape:  (50000, 8)\n",
            "y_c1_test shape:  (10000, 8)\n",
            "y_c2_train shape:  (50000, 20)\n",
            "y_c2_test shape:  (10000, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Flat CNN Base C"
      ],
      "metadata": {
        "id": "4QgJRBAElCsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------- model definition ---------------------------\n",
        "img_input = Input(shape=input_shape, name='input')\n",
        "\n",
        "#--- block 1 ---\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "#--- block 2 ---\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "#--- block 3 ---\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "#--- block 4 ---\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "#--- block 5 ---\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "#--- fine block ---\n",
        "x = Flatten(name='flatten')(x)\n",
        "x = Dense(4096, activation='relu', name='fc_cifar100_1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(4096, activation='relu', name='fc_cifar100_2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "fine_pred = Dense(num_classes, activation='softmax', name='predictions_cifar100')(x)\n",
        "\n",
        "model = Model(img_input, fine_pred, name='Flat_CNN_Base_C')\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "#----------------------- compile and fit ---------------------------\n",
        "sgd = optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=sgd, \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXekb-lIlFkb",
        "outputId": "d7309ef4-3ed9-45a8-80c9-fcb33177dcb2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Flat_CNN_Base_C\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 4, 4, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 4, 4, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 4, 4, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 2, 2, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 2, 2, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 2, 2, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " fc_cifar100_1 (Dense)       (None, 4096)              8392704   \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 4096)             16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " fc_cifar100_2 (Dense)       (None, 4096)              16781312  \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 4096)             16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " predictions_cifar100 (Dense  (None, 100)              409700    \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,348,068\n",
            "Trainable params: 40,323,236\n",
            "Non-trainable params: 24,832\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "change_lr = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Training\n",
        "history_base_c = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=0,\n",
        "          callbacks=change_lr,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluation on test set\n",
        "score_base_c = model.evaluate(x_test, y_test, verbose=0)\n",
        "parameters_base_c = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
        "\n",
        "# Results\n",
        "print(\"--- Flat CNN Base C ---\")\n",
        "print(\"Accuracy:\",score_base_c[1])\n",
        "print(\"Parameters:\",\"{:,}\".format(parameters_base_c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umUqNdkwlXCr",
        "outputId": "9c10cce3-db8c-421f-dca5-c87dea836255"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Flat CNN Base C ---\n",
            "Accuracy: 0.6236000061035156\n",
            "Parameters: 40,323,236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#B-CNN Base C"
      ],
      "metadata": {
        "id": "3AAO2i_3llKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if True, the model uses BT-strategy for training\n",
        "bt_strategy = True"
      ],
      "metadata": {
        "id": "Iu13ILFwmbvC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------- model definition ---------------------------\n",
        "if bt_strategy == True:\n",
        "  alpha = K.variable(value=0.98, dtype=\"float32\", name=\"alpha\") # A1 in paper\n",
        "  beta = K.variable(value=0.01, dtype=\"float32\", name=\"beta\") # A2 in paper\n",
        "  gamma = K.variable(value=0.01, dtype=\"float32\", name=\"gamma\") # A3 in paper\n",
        "else:\n",
        "  alpha = K.variable(value=0.33, dtype=\"float32\", name=\"alpha\") # A1 in paper\n",
        "  beta = K.variable(value=0.33, dtype=\"float32\", name=\"beta\") # A2 in paper\n",
        "  gamma = K.variable(value=0.34, dtype=\"float32\", name=\"gamma\") # A3 in paper  \n",
        "\n",
        "img_input = Input(shape=input_shape, name='input')\n",
        "#--- block 1 ---\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "#--- block 2 ---\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "#--- coarse 1 branch ---\n",
        "c_1_bch = Flatten(name='c1_flatten')(x)\n",
        "c_1_bch = Dense(256, activation='relu', name='c1_fc_cifar10_1')(c_1_bch)\n",
        "c_1_bch = BatchNormalization()(c_1_bch)\n",
        "c_1_bch = Dropout(0.5)(c_1_bch)\n",
        "c_1_bch = Dense(256, activation='relu', name='c1_fc2')(c_1_bch)\n",
        "c_1_bch = BatchNormalization()(c_1_bch)\n",
        "c_1_bch = Dropout(0.5)(c_1_bch)\n",
        "c_1_pred = Dense(coarse1_classes, activation='softmax', name='c1_predictions_cifar10')(c_1_bch)\n",
        "\n",
        "#--- block 3 ---\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "#--- coarse 2 branch ---\n",
        "c_2_bch = Flatten(name='c2_flatten')(x)\n",
        "c_2_bch = Dense(256, activation='relu', name='c2_fc_cifar100_1')(c_2_bch)\n",
        "c_2_bch = BatchNormalization()(c_2_bch)\n",
        "c_2_bch = Dropout(0.5)(c_2_bch)\n",
        "c_2_bch = Dense(256, activation='relu', name='c2_fc2')(c_2_bch)\n",
        "c_2_bch = BatchNormalization()(c_2_bch)\n",
        "c_2_bch = Dropout(0.5)(c_2_bch)\n",
        "c_2_pred = Dense(coarse2_classes, activation='softmax', name='c2_predictions_cifar100')(c_2_bch)\n",
        "\n",
        "#--- block 4 ---\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "\n",
        "#--- block 5 ---\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "#--- fine block ---\n",
        "x = Flatten(name='flatten')(x)\n",
        "x = Dense(256, activation='relu', name='fc_cifar100_1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu', name='fc_cifar100_2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "fine_pred = Dense(num_classes, activation='softmax', name='predictions_cifar100')(x)\n",
        "\n",
        "model = Model(img_input, [c_1_pred, c_2_pred, fine_pred], name='bcnn_base_c')\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "#----------------------- compile and fit ---------------------------\n",
        "sgd = optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=sgd, \n",
        "              loss_weights=[alpha, beta, gamma], \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OUdd3hblrnF",
        "outputId": "efa7256a-66db-4c33-ee5c-880fed5c1f4c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"bcnn_base_c\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 32, 32, 64)   1792        ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 32, 32, 64)  256         ['block1_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 32, 32, 64)   36928       ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 32, 32, 64)  256         ['block1_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 16, 16, 64)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 16, 16, 128)  73856       ['block1_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 128)  512        ['block2_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 16, 16, 128)  147584      ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 128)  512        ['block2_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 8, 8, 128)    0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 8, 8, 256)    295168      ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 8, 8, 256)   1024        ['block3_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 8, 8, 256)    590080      ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 8, 8, 256)   1024        ['block3_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 8, 8, 256)    590080      ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 8, 8, 256)   1024        ['block3_conv3[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 4, 4, 512)    1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 4, 4, 512)   2048        ['block4_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 4, 4, 512)    2359808     ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 4, 4, 512)   2048        ['block4_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 4, 4, 512)    2359808     ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 4, 4, 512)   2048        ['block4_conv3[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 2, 2, 512)    0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 2, 2, 512)    2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 2, 2, 512)   2048        ['block5_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 2, 2, 512)    2359808     ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 2, 2, 512)   2048        ['block5_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 2, 2, 512)    2359808     ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 2, 2, 512)   2048        ['block5_conv3[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " c1_flatten (Flatten)           (None, 8192)         0           ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " c2_flatten (Flatten)           (None, 4096)         0           ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " c1_fc_cifar10_1 (Dense)        (None, 256)          2097408     ['c1_flatten[0][0]']             \n",
            "                                                                                                  \n",
            " c2_fc_cifar100_1 (Dense)       (None, 256)          1048832     ['c2_flatten[0][0]']             \n",
            "                                                                                                  \n",
            " fc_cifar100_1 (Dense)          (None, 256)          524544      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 256)         1024        ['c1_fc_cifar10_1[0][0]']        \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 256)         1024        ['c2_fc_cifar100_1[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 256)         1024        ['fc_cifar100_1[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 256)          0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 256)          0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 256)          0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " c1_fc2 (Dense)                 (None, 256)          65792       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " c2_fc2 (Dense)                 (None, 256)          65792       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " fc_cifar100_2 (Dense)          (None, 256)          65792       ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 256)         1024        ['c1_fc2[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 256)         1024        ['c2_fc2[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 256)         1024        ['fc_cifar100_2[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 256)          0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 256)          0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 256)          0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " c1_predictions_cifar10 (Dense)  (None, 8)           2056        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " c2_predictions_cifar100 (Dense  (None, 20)          5140        ['dropout_5[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " predictions_cifar100 (Dense)   (None, 100)          25700       ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18,638,784\n",
            "Trainable params: 18,627,264\n",
            "Non-trainable params: 11,520\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks \n",
        "change_lr = LearningRateScheduler(scheduler)\n",
        "change_lw = LossWeightsModifier(alpha, beta, gamma)\n",
        "\n",
        "if bt_strategy == True:\n",
        "  cbks = [change_lr, change_lw]\n",
        "else:\n",
        "  cbks = [change_lr]\n",
        "\n",
        "history_bcnn_c = model.fit(x_train, [y_c1_train, y_c2_train, y_train],\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=0,\n",
        "          callbacks=cbks,\n",
        "          validation_data=(x_test, [y_c1_test, y_c2_test, y_test]))\n",
        "\n",
        "score_b_cnn_c = model.evaluate(x_test, [y_c1_test, y_c2_test, y_test], verbose=0)\n",
        "parameters_b_cnn_c = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "preci_b_cnn_c,reca_b_cnn_c,f1_b_cnn_c= hierarchical_metrics([y_c1_test, y_c2_test, y_test],predictions)\n",
        "\n",
        "# Results\n",
        "print(\"--- B-CNN Base C ---\")\n",
        "print(\"--- Accuracy per level ---\")\n",
        "print(\"Accuracy level 1:\",score_b_cnn_c[4])\n",
        "print(\"Accuracy level 2:\",score_b_cnn_c[5])\n",
        "print(\"Accuracy level 3:\",score_b_cnn_c[6])\n",
        "print(\"--- Hierarchical Metrics ---\")\n",
        "print(\"Precision:\",preci_b_cnn_c)\n",
        "print(\"Recall:\",reca_b_cnn_c)\n",
        "print(\"f1:\",f1_b_cnn_c)\n",
        "print(\"Parameters:\",\"{:,}\".format(parameters_b_cnn_c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBFZX4nemlEM",
        "outputId": "2f4c71b5-c138-4ce3-94de-73d35f88252d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- B-CNN Base C ---\n",
            "--- Accuracy per level ---\n",
            "Accuracy level 1: 0.7196000218391418\n",
            "Accuracy level 2: 0.6848000288009644\n",
            "Accuracy level 3: 0.6380000114440918\n",
            "--- Hierarchical Metrics ---\n",
            "Precision: 0.6950770489567708\n",
            "Recall: 0.6958361774744027\n",
            "f1: 0.6954564060581253\n",
            "Parameters: 18,627,264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BA-CNN Base C\n"
      ],
      "metadata": {
        "id": "K1Q6T--Rm7n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if True, the model uses BT-strategy for training\n",
        "bt_strategy = True\n",
        "\n",
        "# neurons of all dense layers on each branch \n",
        "branch_neurons = 256"
      ],
      "metadata": {
        "id": "rjdWeCDFnE6d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------- model definition ---------------------------\n",
        "if bt_strategy == True:\n",
        "  alpha = K.variable(value=0.98, dtype=\"float32\", name=\"alpha\") # A1 in paper\n",
        "  beta = K.variable(value=0.01, dtype=\"float32\", name=\"beta\") # A2 in paper\n",
        "  gamma = K.variable(value=0.01, dtype=\"float32\", name=\"gamma\") # A3 in paper\n",
        "else:\n",
        "  alpha = K.variable(value=0.33, dtype=\"float32\", name=\"alpha\") # A1 in paper\n",
        "  beta = K.variable(value=0.33, dtype=\"float32\", name=\"beta\") # A2 in paper\n",
        "  gamma = K.variable(value=0.34, dtype=\"float32\", name=\"gamma\") # A3 in paper  \n",
        "\n",
        "img_input = Input(shape=input_shape, name='input')\n",
        "#--- block 1 ---\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "#--- block 2 ---\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "#--- coarse 1 branch ---\n",
        "c_1_bch = Flatten(name='c1_flatten')(x)\n",
        "c_1_bch = Dense(branch_neurons, activation='relu', name='c1_fc_cifar10_1')(c_1_bch)\n",
        "c_1_bch = BatchNormalization()(c_1_bch)\n",
        "c_1_bch = Dropout(0.5)(c_1_bch)\n",
        "c_1_bch = Dense(branch_neurons, activation='relu', name='c1_fc2')(c_1_bch)\n",
        "c_1_bch = BatchNormalization()(c_1_bch)\n",
        "c_1_bch = Dropout(0.5)(c_1_bch)\n",
        "#c_1_pred = Dense(coarse1_classes, activation='softmax', name='c1_predictions_cifar10')(c_1_bch)\n",
        "\n",
        "#--- block 3 ---\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "#--- coarse 2 branch ---\n",
        "c_2_bch = Flatten(name='c2_flatten')(x)\n",
        "c_2_bch = Dense(branch_neurons, activation='relu', name='c2_fc_cifar100_1')(c_2_bch)\n",
        "c_2_bch = BatchNormalization()(c_2_bch)\n",
        "c_2_bch = Dropout(0.5)(c_2_bch)\n",
        "c_2_bch = Dense(branch_neurons, activation='relu', name='c2_fc2')(c_2_bch)\n",
        "c_2_bch = BatchNormalization()(c_2_bch)\n",
        "c_2_bch = Dropout(0.5)(c_2_bch)\n",
        "#c_2_pred = Dense(coarse2_classes, activation='softmax', name='c2_predictions_cifar100')(c_2_bch)\n",
        "\n",
        "#--- block 4 ---\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "\n",
        "#--- block 5 ---\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "#--- fine block ---\n",
        "x = Flatten(name='flatten')(x)\n",
        "x = Dense(branch_neurons, activation='relu', name='fc_cifar100_1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(branch_neurons, activation='relu', name='fc_cifar100_2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "#fine_pred = Dense(num_classes, activation='softmax', name='predictions_cifar100')(x)\n",
        "\n",
        "\n",
        "#-- Att for coarse 1---\n",
        "# Coarse 1\n",
        "sfcn_1_1 = Dense(64, name='fc1_1')(c_1_bch)\n",
        "sfcn_1_1 = Dense(1, name='fc1_2')(sfcn_1_1)\n",
        "# Coarse 2\n",
        "sfcn_1_2 = Dense(64, name='fc1_3')(c_2_bch)\n",
        "sfcn_1_2 = Dense(1, name='fc1_4')(sfcn_1_2)\n",
        "# Fine\n",
        "sfcn_1_3 = Dense(64, name='fc1_5')(x)\n",
        "sfcn_1_3 = Dense(1, name='fc1_6')(sfcn_1_3)\n",
        "\n",
        "score_vector_1 = Concatenate()([sfcn_1_1,sfcn_1_2,sfcn_1_3]) # Score vector 1\n",
        "att_weights_1 = Activation('softmax', name='attention_weights_1')(score_vector_1) # Attention weights 1\n",
        "weightned_sum_1 = Add()([c_1_bch*att_weights_1[0][0],c_2_bch*att_weights_1[0][1],x*att_weights_1[0][2]]) # Weightned sum 1\n",
        "\n",
        "# Concat and prediction\n",
        "coarse_1_concat = Concatenate()([c_1_bch,weightned_sum_1])\n",
        "c_1_pred = Dense(coarse1_classes, activation='softmax', name='c1_predictions_cifar100')(coarse_1_concat)\n",
        "\n",
        "\n",
        "#-- Att for coarse 2---\n",
        "\n",
        "# Coarse 1\n",
        "sfcn_2_1 = Dense(64, name='fc2_1')(c_1_bch)\n",
        "sfcn_2_1 = Dense(1, name='fc2_2')(sfcn_2_1)\n",
        "# Coarse 2\n",
        "sfcn_2_2 = Dense(64, name='fc2_3')(c_2_bch)\n",
        "sfcn_2_2 = Dense(1, name='fc2_4')(sfcn_2_2)\n",
        "# Fine\n",
        "sfcn_2_3 = Dense(64, name='fc2_5')(x)\n",
        "sfcn_2_3 = Dense(1, name='fc2_6')(sfcn_2_3)\n",
        "\n",
        "score_vector_2 = Concatenate()([sfcn_2_1,sfcn_2_2,sfcn_2_3]) # Score vector 1\n",
        "att_weights_2 = Activation('softmax', name='attention_weights_2')(score_vector_2) # Attention weights 1\n",
        "weightned_sum_2 = Add()([c_1_bch*att_weights_2[0][0],c_2_bch*att_weights_2[0][1],x*att_weights_2[0][2]]) # Weightned sum 1\n",
        "\n",
        "# Concat and prediction\n",
        "coarse_2_concat = Concatenate()([c_2_bch,weightned_sum_2])\n",
        "c_2_pred = Dense(coarse2_classes, activation='softmax', name='c2_predictions_cifar100')(coarse_2_concat)\n",
        "\n",
        "\n",
        "#-- Att for fine---\n",
        "\n",
        "# Coarse 1\n",
        "sfcn_3_1 = Dense(64, name='fc3_1')(c_1_bch)\n",
        "sfcn_3_1 = Dense(1, name='fc3_2')(sfcn_3_1)\n",
        "# Coarse 2\n",
        "sfcn_3_2 = Dense(64, name='fc3_3')(c_2_bch)\n",
        "sfcn_3_2 = Dense(1, name='fc3_4')(sfcn_3_2)\n",
        "# Fine\n",
        "sfcn_3_3 = Dense(64, name='fc3_5')(x)\n",
        "sfcn_3_3 = Dense(1, name='fc3_6')(sfcn_3_3)\n",
        "\n",
        "score_vector_3 = Concatenate()([sfcn_3_1,sfcn_3_2,sfcn_3_3]) # Score vector 1\n",
        "att_weights_3 = Activation('softmax', name='attention_weights_3')(score_vector_3) # Attention weights 1\n",
        "weightned_sum_3 = Add()([c_1_bch*att_weights_3[0][0],c_2_bch*att_weights_3[0][1],x*att_weights_3[0][2]]) # Weightned sum 3\n",
        "\n",
        "# Concat and prediction\n",
        "fine_concat = Concatenate()([x,weightned_sum_3])\n",
        "fine_pred = Dense(num_classes, activation='softmax', name='predictions_cifar100')(fine_concat)\n",
        "\n",
        "model = Model(img_input, [c_1_pred, c_2_pred, fine_pred], name='bacnn_base_c')\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "#----------------------- compile and fit ---------------------------\n",
        "sgd = optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=sgd, \n",
        "              loss_weights=[alpha, beta, gamma], \n",
        "              # optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsAMV-VinFS8",
        "outputId": "dfde0a7c-b3d9-47e4-df3a-1803c416782d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"bacnn_base_c\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 32, 32, 64)   1792        ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 32, 32, 64)  256         ['block1_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 32, 32, 64)   36928       ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 32, 32, 64)  256         ['block1_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 16, 16, 64)   0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 16, 16, 128)  73856       ['block1_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 16, 16, 128)  512        ['block2_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 16, 16, 128)  147584      ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 16, 16, 128)  512        ['block2_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 8, 8, 128)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 8, 8, 256)    295168      ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 8, 8, 256)   1024        ['block3_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 8, 8, 256)    590080      ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 8, 8, 256)   1024        ['block3_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 8, 8, 256)    590080      ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 8, 8, 256)   1024        ['block3_conv3[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 4, 4, 512)    1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 4, 4, 512)   2048        ['block4_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 4, 4, 512)    2359808     ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 4, 4, 512)   2048        ['block4_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 4, 4, 512)    2359808     ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 4, 4, 512)   2048        ['block4_conv3[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 2, 2, 512)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 2, 2, 512)    2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 2, 2, 512)   2048        ['block5_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 2, 2, 512)    2359808     ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 2, 2, 512)   2048        ['block5_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 2, 2, 512)    2359808     ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 2, 2, 512)   2048        ['block5_conv3[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " c1_flatten (Flatten)           (None, 8192)         0           ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " c2_flatten (Flatten)           (None, 4096)         0           ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " c1_fc_cifar10_1 (Dense)        (None, 256)          2097408     ['c1_flatten[0][0]']             \n",
            "                                                                                                  \n",
            " c2_fc_cifar100_1 (Dense)       (None, 256)          1048832     ['c2_flatten[0][0]']             \n",
            "                                                                                                  \n",
            " fc_cifar100_1 (Dense)          (None, 256)          524544      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 256)         1024        ['c1_fc_cifar10_1[0][0]']        \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 256)         1024        ['c2_fc_cifar100_1[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 256)         1024        ['fc_cifar100_1[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 256)          0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 256)          0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 256)          0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " c1_fc2 (Dense)                 (None, 256)          65792       ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " c2_fc2 (Dense)                 (None, 256)          65792       ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " fc_cifar100_2 (Dense)          (None, 256)          65792       ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 256)         1024        ['c1_fc2[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 256)         1024        ['c2_fc2[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 256)         1024        ['fc_cifar100_2[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 256)          0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 256)          0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 256)          0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " fc1_1 (Dense)                  (None, 64)           16448       ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " fc1_3 (Dense)                  (None, 64)           16448       ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            " fc1_5 (Dense)                  (None, 64)           16448       ['dropout_13[0][0]']             \n",
            "                                                                                                  \n",
            " fc2_1 (Dense)                  (None, 64)           16448       ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " fc2_3 (Dense)                  (None, 64)           16448       ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            " fc2_5 (Dense)                  (None, 64)           16448       ['dropout_13[0][0]']             \n",
            "                                                                                                  \n",
            " fc3_1 (Dense)                  (None, 64)           16448       ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " fc3_3 (Dense)                  (None, 64)           16448       ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            " fc3_5 (Dense)                  (None, 64)           16448       ['dropout_13[0][0]']             \n",
            "                                                                                                  \n",
            " fc1_2 (Dense)                  (None, 1)            65          ['fc1_1[0][0]']                  \n",
            "                                                                                                  \n",
            " fc1_4 (Dense)                  (None, 1)            65          ['fc1_3[0][0]']                  \n",
            "                                                                                                  \n",
            " fc1_6 (Dense)                  (None, 1)            65          ['fc1_5[0][0]']                  \n",
            "                                                                                                  \n",
            " fc2_2 (Dense)                  (None, 1)            65          ['fc2_1[0][0]']                  \n",
            "                                                                                                  \n",
            " fc2_4 (Dense)                  (None, 1)            65          ['fc2_3[0][0]']                  \n",
            "                                                                                                  \n",
            " fc2_6 (Dense)                  (None, 1)            65          ['fc2_5[0][0]']                  \n",
            "                                                                                                  \n",
            " fc3_2 (Dense)                  (None, 1)            65          ['fc3_1[0][0]']                  \n",
            "                                                                                                  \n",
            " fc3_4 (Dense)                  (None, 1)            65          ['fc3_3[0][0]']                  \n",
            "                                                                                                  \n",
            " fc3_6 (Dense)                  (None, 1)            65          ['fc3_5[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3)            0           ['fc1_2[0][0]',                  \n",
            "                                                                  'fc1_4[0][0]',                  \n",
            "                                                                  'fc1_6[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 3)            0           ['fc2_2[0][0]',                  \n",
            "                                                                  'fc2_4[0][0]',                  \n",
            "                                                                  'fc2_6[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 3)            0           ['fc3_2[0][0]',                  \n",
            "                                                                  'fc3_4[0][0]',                  \n",
            "                                                                  'fc3_6[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_weights_1 (Activatio  (None, 3)           0           ['concatenate[0][0]']            \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " attention_weights_2 (Activatio  (None, 3)           0           ['concatenate_2[0][0]']          \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " attention_weights_3 (Activatio  (None, 3)           0           ['concatenate_4[0][0]']          \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (3,)                0           ['attention_weights_1[0][0]']    \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  (3,)                0           ['attention_weights_1[0][0]']    \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4 (Sl  (3,)                0           ['attention_weights_1[0][0]']    \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_6 (Sl  (3,)                0           ['attention_weights_2[0][0]']    \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_8 (Sl  (3,)                0           ['attention_weights_2[0][0]']    \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_10 (S  (3,)                0           ['attention_weights_2[0][0]']    \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_12 (S  (3,)                0           ['attention_weights_3[0][0]']    \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_14 (S  (3,)                0           ['attention_weights_3[0][0]']    \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_16 (S  (3,)                0           ['attention_weights_3[0][0]']    \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  ()                  0           ['tf.__operators__.getitem[0][0]'\n",
            " icingOpLambda)                                                  ]                                \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3 (Sl  ()                  0           ['tf.__operators__.getitem_2[0][0\n",
            " icingOpLambda)                                                  ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_5 (Sl  ()                  0           ['tf.__operators__.getitem_4[0][0\n",
            " icingOpLambda)                                                  ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7 (Sl  ()                  0           ['tf.__operators__.getitem_6[0][0\n",
            " icingOpLambda)                                                  ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_9 (Sl  ()                  0           ['tf.__operators__.getitem_8[0][0\n",
            " icingOpLambda)                                                  ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_11 (S  ()                  0           ['tf.__operators__.getitem_10[0][\n",
            " licingOpLambda)                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_13 (S  ()                  0           ['tf.__operators__.getitem_12[0][\n",
            " licingOpLambda)                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_15 (S  ()                  0           ['tf.__operators__.getitem_14[0][\n",
            " licingOpLambda)                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_17 (S  ()                  0           ['tf.__operators__.getitem_16[0][\n",
            " licingOpLambda)                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None, 256)          0           ['dropout_9[0][0]',              \n",
            "                                                                  'tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLambda  (None, 256)         0           ['dropout_11[0][0]',             \n",
            " )                                                                'tf.__operators__.getitem_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_2 (TFOpLambda  (None, 256)         0           ['dropout_13[0][0]',             \n",
            " )                                                                'tf.__operators__.getitem_5[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLambda  (None, 256)         0           ['dropout_9[0][0]',              \n",
            " )                                                                'tf.__operators__.getitem_7[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_4 (TFOpLambda  (None, 256)         0           ['dropout_11[0][0]',             \n",
            " )                                                                'tf.__operators__.getitem_9[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_5 (TFOpLambda  (None, 256)         0           ['dropout_13[0][0]',             \n",
            " )                                                                'tf.__operators__.getitem_11[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_6 (TFOpLambda  (None, 256)         0           ['dropout_9[0][0]',              \n",
            " )                                                                'tf.__operators__.getitem_13[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_7 (TFOpLambda  (None, 256)         0           ['dropout_11[0][0]',             \n",
            " )                                                                'tf.__operators__.getitem_15[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLambda  (None, 256)         0           ['dropout_13[0][0]',             \n",
            " )                                                                'tf.__operators__.getitem_17[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 256)          0           ['tf.math.multiply[0][0]',       \n",
            "                                                                  'tf.math.multiply_1[0][0]',     \n",
            "                                                                  'tf.math.multiply_2[0][0]']     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 256)          0           ['tf.math.multiply_3[0][0]',     \n",
            "                                                                  'tf.math.multiply_4[0][0]',     \n",
            "                                                                  'tf.math.multiply_5[0][0]']     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 256)          0           ['tf.math.multiply_6[0][0]',     \n",
            "                                                                  'tf.math.multiply_7[0][0]',     \n",
            "                                                                  'tf.math.multiply_8[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 512)          0           ['dropout_9[0][0]',              \n",
            "                                                                  'add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 512)          0           ['dropout_11[0][0]',             \n",
            "                                                                  'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 512)          0           ['dropout_13[0][0]',             \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " c1_predictions_cifar100 (Dense  (None, 8)           4104        ['concatenate_1[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " c2_predictions_cifar100 (Dense  (None, 20)          10260       ['concatenate_3[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " predictions_cifar100 (Dense)   (None, 100)          51300       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18,820,169\n",
            "Trainable params: 18,808,649\n",
            "Non-trainable params: 11,520\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks \n",
        "change_lr = LearningRateScheduler(scheduler)\n",
        "change_lw = LossWeightsModifier(alpha, beta, gamma)\n",
        "\n",
        "if bt_strategy == True:\n",
        "  cbks = [change_lr, change_lw]\n",
        "else:\n",
        "  cbks = [change_lr]\n",
        "\n",
        "history_bcnn_b = model.fit(x_train, [y_c1_train, y_c2_train, y_train],\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=0,\n",
        "          callbacks=cbks,\n",
        "          validation_data=(x_test, [y_c1_test, y_c2_test, y_test]))\n",
        "\n",
        "score_ba_cnn_c = model.evaluate(x_test, [y_c1_test, y_c2_test, y_test], verbose=0)\n",
        "parameters_ba_cnn_c = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "preci_ba_cnn_c,reca_ba_cnn_c,f1_ba_cnn_c= hierarchical_metrics([y_c1_test, y_c2_test, y_test],predictions)\n",
        "\n",
        "# Results\n",
        "print(\"--- BA-CNN Base C ---\")\n",
        "print(\"--- Accuracy per level ---\")\n",
        "print(\"Accuracy level 1:\",score_ba_cnn_c[4])\n",
        "print(\"Accuracy level 2:\",score_ba_cnn_c[5])\n",
        "print(\"Accuracy level 3:\",score_ba_cnn_c[6])\n",
        "print(\"--- Hierarchical Metrics ---\")\n",
        "print(\"Precision:\",preci_ba_cnn_c)\n",
        "print(\"Recall:\",reca_ba_cnn_c)\n",
        "print(\"f1:\",f1_ba_cnn_c)\n",
        "print(\"Parameters:\",\"{:,}\".format(parameters_ba_cnn_c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrcUqi9pnsMT",
        "outputId": "f7ad8867-5e67-48b0-94c1-ac03252b1267"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- BA-CNN Base C ---\n",
            "--- Accuracy per level ---\n",
            "Accuracy level 1: 0.8359000086784363\n",
            "Accuracy level 2: 0.7408000230789185\n",
            "Accuracy level 3: 0.6186000108718872\n",
            "--- Hierarchical Metrics ---\n",
            "Precision: 0.7414368403132449\n",
            "Recall: 0.7432081911262799\n",
            "f1: 0.7423214590080109\n",
            "Parameters: 18,808,649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#H-CNN Base C"
      ],
      "metadata": {
        "id": "VjnFXa29nvcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if True, the model uses BT-strategy for training\n",
        "bt_strategy = True"
      ],
      "metadata": {
        "id": "0JjFhDFFnx9j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------- model definition ---------------------------\n",
        "if bt_strategy == True:\n",
        "  alpha = K.variable(value=0.98, dtype=\"float32\", name=\"alpha\") # A1 in paper\n",
        "  beta = K.variable(value=0.01, dtype=\"float32\", name=\"beta\") # A2 in paper\n",
        "  gamma = K.variable(value=0.01, dtype=\"float32\", name=\"gamma\") # A3 in paper\n",
        "else:\n",
        "  alpha = K.variable(value=0.33, dtype=\"float32\", name=\"alpha\") # A1 in paper\n",
        "  beta = K.variable(value=0.33, dtype=\"float32\", name=\"beta\") # A2 in paper\n",
        "  gamma = K.variable(value=0.34, dtype=\"float32\", name=\"gamma\") # A3 in paper \n",
        "\n",
        "img_input = Input(shape=input_shape, name='input')\n",
        "\n",
        "#--- block 1 ---\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "#--- block 2 ---\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "#--- coarse 1 branch ---\n",
        "c_1_bch_flatt = Flatten(name='c1_flatten')(x)\n",
        "c_1_bch = Dense(256, activation='relu', name='c1_fc_cifar10_1')(c_1_bch_flatt)\n",
        "c_1_bch = BatchNormalization()(c_1_bch)\n",
        "c_1_bch = Dropout(0.5)(c_1_bch)\n",
        "c_1_bch = Dense(256, activation='relu', name='c1_fc2')(c_1_bch)\n",
        "c_1_bch = BatchNormalization()(c_1_bch)\n",
        "c_1_bch = Dropout(0.5)(c_1_bch)\n",
        "c_1_pred = Dense(coarse1_classes, activation='softmax', name='c1_predictions_cifar10')(c_1_bch)\n",
        "\n",
        "#--- block 3 ---\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "#--- coarse 2 branch ---\n",
        "c_2_bch_flatt = Flatten(name='c2_flatten')(x)\n",
        "c_2_bch_concat = Concatenate()([c_1_bch_flatt,c_2_bch_flatt]) # Conectivity Pattern\n",
        "c_2_bch = Dense(1024, activation='relu', name='c2_fc_cifar100_1')(c_2_bch_concat)\n",
        "c_2_bch = BatchNormalization()(c_2_bch)\n",
        "c_2_bch = Dropout(0.5)(c_2_bch)\n",
        "c_2_bch = Dense(1024, activation='relu', name='c2_fc2')(c_2_bch)\n",
        "c_2_bch = BatchNormalization()(c_2_bch)\n",
        "c_2_bch = Dropout(0.5)(c_2_bch)\n",
        "c_2_pred = Dense(coarse2_classes, activation='softmax', name='c2_predictions_cifar100')(c_2_bch)\n",
        "\n",
        "\n",
        "#--- block 4 ---\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "\n",
        "#--- block 5 ---\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "#--- coarse 3(Fine) ---\n",
        "\n",
        "x_flatt = Flatten(name='flatten')(x)\n",
        "x = Concatenate()([c_2_bch_concat,x_flatt]) # Conectivity Pattern\n",
        "x = Dense(4096, activation='relu', name='fc_1_cifar100')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(4096, activation='relu', name='fc_2_cifar100')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "c_3_pred = Dense(num_classes, activation='softmax', name='c_3_2_predictions_cifar100')(x)\n",
        "\n",
        "model = Model(img_input, [c_1_pred,c_2_pred,c_3_pred], name='hcnn_base_c')\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "#----------------------- compile and fit ---------------------------\n",
        "sgd = optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=sgd, \n",
        "              loss_weights=[alpha,beta,gamma], \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2rWS0PJn1OJ",
        "outputId": "c5810b09-d521-4071-de82-2268c564836e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"hcnn_base_c\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 32, 32, 64)   1792        ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 32, 32, 64)  256         ['block1_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 32, 32, 64)   36928       ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 32, 32, 64)  256         ['block1_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 16, 16, 64)   0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 16, 16, 128)  73856       ['block1_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 16, 16, 128)  512        ['block2_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 16, 16, 128)  147584      ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 16, 16, 128)  512        ['block2_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 8, 8, 128)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 8, 8, 256)    295168      ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 8, 8, 256)   1024        ['block3_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 8, 8, 256)    590080      ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 8, 8, 256)   1024        ['block3_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 8, 8, 256)    590080      ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 8, 8, 256)   1024        ['block3_conv3[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 4, 4, 512)    1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 4, 4, 512)   2048        ['block4_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 4, 4, 512)    2359808     ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 4, 4, 512)   2048        ['block4_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 4, 4, 512)    2359808     ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 4, 4, 512)   2048        ['block4_conv3[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 2, 2, 512)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 2, 2, 512)    2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 2, 2, 512)   2048        ['block5_conv1[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 2, 2, 512)    2359808     ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 2, 2, 512)   2048        ['block5_conv2[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 2, 2, 512)    2359808     ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " c1_flatten (Flatten)           (None, 8192)         0           ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " c2_flatten (Flatten)           (None, 4096)         0           ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 2, 2, 512)   2048        ['block5_conv3[0][0]']           \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 12288)        0           ['c1_flatten[0][0]',             \n",
            "                                                                  'c2_flatten[0][0]']             \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 14336)        0           ['concatenate_6[0][0]',          \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " c1_fc_cifar10_1 (Dense)        (None, 256)          2097408     ['c1_flatten[0][0]']             \n",
            "                                                                                                  \n",
            " c2_fc_cifar100_1 (Dense)       (None, 1024)         12583936    ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " fc_1_cifar100 (Dense)          (None, 4096)         58724352    ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 256)         1024        ['c1_fc_cifar10_1[0][0]']        \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 1024)        4096        ['c2_fc_cifar100_1[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 4096)        16384       ['fc_1_cifar100[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 256)          0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 1024)         0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 4096)         0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " c1_fc2 (Dense)                 (None, 256)          65792       ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " c2_fc2 (Dense)                 (None, 1024)         1049600     ['dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            " fc_2_cifar100 (Dense)          (None, 4096)         16781312    ['dropout_18[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 256)         1024        ['c1_fc2[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 1024)        4096        ['c2_fc2[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 4096)        16384       ['fc_2_cifar100[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 256)          0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 1024)         0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 4096)         0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " c1_predictions_cifar10 (Dense)  (None, 8)           2056        ['dropout_15[0][0]']             \n",
            "                                                                                                  \n",
            " c2_predictions_cifar100 (Dense  (None, 20)          20500       ['dropout_17[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " c_3_2_predictions_cifar100 (De  (None, 100)         409700      ['dropout_19[0][0]']             \n",
            " nse)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 106,509,248\n",
            "Trainable params: 106,479,296\n",
            "Non-trainable params: 29,952\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks \n",
        "change_lr = LearningRateScheduler(scheduler)\n",
        "change_lw = LossWeightsModifier(alpha, beta, gamma)\n",
        "\n",
        "if bt_strategy == True:\n",
        "  cbks = [change_lr, change_lw]\n",
        "else:\n",
        "  cbks = [change_lr]\n",
        "\n",
        "history_bcnn_b = model.fit(x_train, [y_c1_train, y_c2_train, y_train],\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=0,\n",
        "          callbacks=cbks,\n",
        "          validation_data=(x_test, [y_c1_test, y_c2_test, y_test]))\n",
        "\n",
        "score_h_cnn_c = model.evaluate(x_test, [y_c1_test, y_c2_test, y_test], verbose=0)\n",
        "parameters_h_cnn_c = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "preci_h_cnn_c,reca_h_cnn_c,f1_h_cnn_c= hierarchical_metrics([y_c1_test, y_c2_test, y_test],predictions)\n",
        "\n",
        "# Results\n",
        "print(\"--- H-CNN Base C ---\")\n",
        "print(\"--- Accuracy per level ---\")\n",
        "print(\"Accuracy level 1:\",score_h_cnn_c[4])\n",
        "print(\"Accuracy level 2:\",score_h_cnn_c[5])\n",
        "print(\"Accuracy level 3:\",score_h_cnn_c[6])\n",
        "print(\"--- Hierarchical Metrics ---\")\n",
        "print(\"Precision:\",preci_h_cnn_c)\n",
        "print(\"Recall:\",reca_h_cnn_c)\n",
        "print(\"f1:\",f1_h_cnn_c)\n",
        "print(\"Parameters:\",\"{:,}\".format(parameters_h_cnn_c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3TLgvXqoGF3",
        "outputId": "21aad2ef-35dc-4425-fbbf-4eca8682a7b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- H-CNN Base C ---\n",
            "--- Accuracy per level ---\n",
            "Accuracy level 1: 0.7240999937057495\n",
            "Accuracy level 2: 0.7017999887466431\n",
            "Accuracy level 3: 0.6507999897003174\n",
            "--- Hierarchical Metrics ---\n",
            "Precision: 0.7055617996662239\n",
            "Recall: 0.7070307167235494\n",
            "f1: 0.7062954944511687\n",
            "Parameters: 106,479,296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {
        "id": "4MiHq1pBoKzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = {'':['Flat CNN Base C','B-CNN Base C','BA-CNN Base C','H-CNN Base C'],'Coarse 1': [0,score_b_cnn_c[4],score_ba_cnn_c[4],score_h_cnn_c[4]],'Coarse 2': [0,score_b_cnn_c[5],score_ba_cnn_c[5],score_h_cnn_c[5]],'Fine': [score_base_c[1],score_b_cnn_c[6],score_ba_cnn_c[6],score_h_cnn_c[6]],'Precision':[0,preci_b_cnn_c,preci_ba_cnn_c,preci_h_cnn_c],'Recall':[0,reca_b_cnn_c,reca_ba_cnn_c,reca_h_cnn_c],'f1':[0,f1_b_cnn_c,f1_ba_cnn_c,f1_h_cnn_c],'Parameters': [parameters_base_c ,parameters_b_cnn_c,parameters_ba_cnn_c,parameters_h_cnn_c]}\n",
        "summary = pd.DataFrame(summary)\n",
        "summary['Parameters'] = (summary['Parameters'].astype(float)/1000000).round(2).astype(str) + 'MM'\n",
        "summary = summary.set_index('')\n",
        "summary.style.highlight_max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_SO--Z3ZoMmB",
        "outputId": "0d9b83f7-899f-452c-e614-8a3171089b4f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fdb58ce5e90>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_52142_row0_col6, #T_52142_row2_col0, #T_52142_row2_col1, #T_52142_row2_col3, #T_52142_row2_col4, #T_52142_row2_col5, #T_52142_row3_col2 {\n",
              "  background-color: yellow;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_52142_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >Coarse 1</th>\n",
              "      <th class=\"col_heading level0 col1\" >Coarse 2</th>\n",
              "      <th class=\"col_heading level0 col2\" >Fine</th>\n",
              "      <th class=\"col_heading level0 col3\" >Precision</th>\n",
              "      <th class=\"col_heading level0 col4\" >Recall</th>\n",
              "      <th class=\"col_heading level0 col5\" >f1</th>\n",
              "      <th class=\"col_heading level0 col6\" >Parameters</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" ></th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "      <th class=\"blank col2\" >&nbsp;</th>\n",
              "      <th class=\"blank col3\" >&nbsp;</th>\n",
              "      <th class=\"blank col4\" >&nbsp;</th>\n",
              "      <th class=\"blank col5\" >&nbsp;</th>\n",
              "      <th class=\"blank col6\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_52142_level0_row0\" class=\"row_heading level0 row0\" >Flat CNN Base C</th>\n",
              "      <td id=\"T_52142_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
              "      <td id=\"T_52142_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
              "      <td id=\"T_52142_row0_col2\" class=\"data row0 col2\" >0.623600</td>\n",
              "      <td id=\"T_52142_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
              "      <td id=\"T_52142_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
              "      <td id=\"T_52142_row0_col5\" class=\"data row0 col5\" >0.000000</td>\n",
              "      <td id=\"T_52142_row0_col6\" class=\"data row0 col6\" >40.32MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_52142_level0_row1\" class=\"row_heading level0 row1\" >B-CNN Base C</th>\n",
              "      <td id=\"T_52142_row1_col0\" class=\"data row1 col0\" >0.719600</td>\n",
              "      <td id=\"T_52142_row1_col1\" class=\"data row1 col1\" >0.684800</td>\n",
              "      <td id=\"T_52142_row1_col2\" class=\"data row1 col2\" >0.638000</td>\n",
              "      <td id=\"T_52142_row1_col3\" class=\"data row1 col3\" >0.695077</td>\n",
              "      <td id=\"T_52142_row1_col4\" class=\"data row1 col4\" >0.695836</td>\n",
              "      <td id=\"T_52142_row1_col5\" class=\"data row1 col5\" >0.695456</td>\n",
              "      <td id=\"T_52142_row1_col6\" class=\"data row1 col6\" >18.63MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_52142_level0_row2\" class=\"row_heading level0 row2\" >BA-CNN Base C</th>\n",
              "      <td id=\"T_52142_row2_col0\" class=\"data row2 col0\" >0.835900</td>\n",
              "      <td id=\"T_52142_row2_col1\" class=\"data row2 col1\" >0.740800</td>\n",
              "      <td id=\"T_52142_row2_col2\" class=\"data row2 col2\" >0.618600</td>\n",
              "      <td id=\"T_52142_row2_col3\" class=\"data row2 col3\" >0.741437</td>\n",
              "      <td id=\"T_52142_row2_col4\" class=\"data row2 col4\" >0.743208</td>\n",
              "      <td id=\"T_52142_row2_col5\" class=\"data row2 col5\" >0.742321</td>\n",
              "      <td id=\"T_52142_row2_col6\" class=\"data row2 col6\" >18.81MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_52142_level0_row3\" class=\"row_heading level0 row3\" >H-CNN Base C</th>\n",
              "      <td id=\"T_52142_row3_col0\" class=\"data row3 col0\" >0.724100</td>\n",
              "      <td id=\"T_52142_row3_col1\" class=\"data row3 col1\" >0.701800</td>\n",
              "      <td id=\"T_52142_row3_col2\" class=\"data row3 col2\" >0.650800</td>\n",
              "      <td id=\"T_52142_row3_col3\" class=\"data row3 col3\" >0.705562</td>\n",
              "      <td id=\"T_52142_row3_col4\" class=\"data row3 col4\" >0.707031</td>\n",
              "      <td id=\"T_52142_row3_col5\" class=\"data row3 col5\" >0.706295</td>\n",
              "      <td id=\"T_52142_row3_col6\" class=\"data row3 col6\" >106.48MM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}